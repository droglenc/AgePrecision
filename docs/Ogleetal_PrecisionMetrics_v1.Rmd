---
title: "Review of Age Precision Metrics with Recommendations for Future Use"
author: ""
date: ""
header-includes:
  - \usepackage{amssymb,amsmath,amsfonts}
output:
  word_document: 
    reference_docx: TAFS_doublespace_Style.docx
    pandoc_args: [--filter, pandoc-crossref]
csl: american-fisheries-society.csl
bibliography: GeneralResources.bib
---

```{r notes, echo=FALSE, eval=FALSE}
#* one and two hashtags demark the first two levels of headings
#* three hashtags ... title
#* four hashtags ...
#* five and six hashtags were used for authors
#* seven hastags were used for lines like running head
#* eight hashtags was used to make a comment box. 
#* nine hashtags makes a pagebreak

#* Scientific names in bibliography will be mis-capitalized
#* Paragraphs should be indented, but this was problematic after equations

#* Had to put pandoc-crossref into RStudio's pandoc folder and add
#*  pandoc_args: [--filter, pandoc-crossref] to YAML when equations were
#*  numbered, which is no longer the case.
```

```{r setup, echo=FALSE, include=FALSE, message=FALSE}
## General setup
knitr::opts_chunk$set(echo=FALSE, results="hide",message=FALSE,warning=FALSE)
wdir <- here::here()
library(ggplot2)
library(dplyr)
source(file.path(wdir,"code","ggplot_theme.R"))  # Get ggplot theme
# figure widths and heights for 1- and 2-column figures
fw1 <- fh1 <- 3.5
fw2 <- 7.25
fh2 <- 7.25*(3/4)
# toggle on to save TIFF/PDF files
saveTIFFs <- TRUE
savePDFs <- TRUE
# setup captioning (need github version ... remotes::install_github('adletaw/captioner')  )
figs <- captioner::captioner(prefix="Figure",suffix=".")

## Helper function
# Simplifies rounding of in-line result values
RES <- function(x,digits=1) formatC(x,format="f",digits=digits)

## Get data
# Must run LitReview_PREPPER.R script prior to this to retrieve the data from
#   GoogleScholar and wrangle it into the needed format which is printed out to
#   the LR RDATA file that is read in below.
load(file.path(wdir,"data","LitReview.RData"))

# data.frame of individual studies (not by precision estimate) ... includes ...
#   variables that identify which metrics were used
LRBS <- LR %>%
  group_by(studyID,pubyear,pubyear5) %>%
  summarize(across(c(APE,ACV,APE2,ACV2,AD,AAD,ASD,PA0,PA1),
                   ~!all(is.na(.)))) %>%
  mutate(PA=PA0 | PA1) %>%
  ungroup()
```

##### Derek H. Ogle
###### Department of Mathematical Sciences and Department of Natural Resources, Northland College, 1411 Ellis Ave, Ashland, WI 54806

##### Joshua XX. Lyons
###### Department of Natural Resources, Northland College, 1411 Ellis Ave, Ashland, WI 54806

####### Running head: Age Precision Metrics Review


#########

# Abstract

######## WILL BE <300 WORDS HERE


#########

# Introduction

Age, along with length, is one of the most important characterisitics of individual fish recorded by fisheries scientists. Age data is used to estimate growth, mortality, and recruitment [@spurgeonGlobalStatusFreshwater2015; @kernsHistoryImportanceAge2017; @quistAgeGrowthFishes2017], which are primary rates of interest for fisheries scientists [@rickerComputationInterpretationBiological1975; @hilbornQuantitativeFisheriesStock1992; @haddonModellingQuantitativeMethods2011; @paukertAgeStructure2017], and in age-structured population models to estimate yield and set harvest regulations [@bevertonDynamicsExploitedFish1957; @hilbornQuantitativeFisheriesStock1992; @haddonModellingQuantitativeMethods2011; @methotStockSynthesisBiological2013]. Age, unlike length, is not directly observed but is most often interpreted from periods of fast and slow growth recorded on calcified structures such as scales, otoliths, fin rays or spines, or vertebrae [@campanaAccuracyPrecisionQuality2001; @spurgeonGlobalStatusFreshwater2015; @quistAgeGrowthFishes2017]. Age data can be highly variable and prone to errors as age may not be reliably recorded on or interpreted from calcified structures, especially for fish that are more than only a few years old [@campanaAccuracyPrecisionQuality2001; @quistAgeGrowth2012; @phelpsChoiceStructureEstimating2017]. Errors in age data have resulted in incorrect estimates of growth, mortality, and recruitment which have led to misunderstanding the population dynamics of some fish populations [@linlaiEffectsAgeingErrors1987; @reevesSimulationStudyImplications2003; @bertignacConsequencesBiasAge2007; @yuleHowSystematicAge2008; @koenigsImpactsAgingError2013; @hamelVariabilityAgeEstimation2016; @tyszko_comparing_2017; @changEvaluationEffectsOtolith2019].

Sources of error in age estimation may be inherent to the calcified structure itself or part of the process of interpreting age from the calcified structure [@campanaAccuracyPrecisionQuality2001; @morisonQualityIssuesUse2005; @buckmeierValidationAnnualDaily2017]. Errors inherent to the structure are measurable, but cannot be controlled [@morisonQualityIssuesUse2005]. Assessing this source of error is part of validating ages estimated from calcified structures, methods for which have been thoroughly reviewed [@maceinaCurrentStatusReview2007; @spurgeonGlobalStatusFreshwater2015; @buckmeierValidationAnnualDaily2017] and are not addressed further here. Errors related to the process of interpreting ages can be both measured and controlled [@morisonQualityIssuesUse2005] and consist of differences between the estimated and true age (i.e., accuracy) and differences among estimated ages from multiple interpretations of the same structure (either by multiple interpreters or the same interpreter multiple times). Differences among interpretations of the same structure may be systematic (e.g., one set of ages is always one year less than the other set of ages), patterned (e.g., one set of ages largely match the other set of ages up to a certain age and then become progressively more different after that age), or random. Identifying or measuring systematic or patterned differences among interpretations is referred to as identifying *bias* (or not) in the age estimates [@campanaGraphicalStatisticalMethods1995]. Methods for assessing bias are described by @campanaGraphicalStatisticalMethods1995 and are also not discussed further here. In the absence of bias, *precision* is a measure of random differences among interpretations, or the repeatability of age estimates among interpreters [@campanaAccuracyPrecisionQuality2001; @maceinaCurrentStatusReview2007] that do not display a bias [@campanaGraphicalStatisticalMethods1995]. Precision and metrics for assessing precision are the focus this paper.

Precision metrics measure the repeatability of $R$ age estimates made on each of $n$ individual fish. Percent agreement, the simplest precision metric, is the percentage of $n$ fish for which the $R$ age estimates are the same (i.e., *exact percent agreement*) or differ by no more than a certain amount (e.g., differ by no more than one year). When $R\!>\!2$, *percent partial agreement* is the percentage of $n$ fish for which the ages agree for some specific number of interpreters (e.g., at least two interpreters agree).

Other measures of precision result from computing various measures of variability among the $R$ age estimates within each of the $j$ fish and then averaging these values across the $n$ fish. The first two measures of variability are the familiar absolute deviation (AD) and standard deviation (SD) of estimated ages for each fish; i.e., 

$$AD_{j} = \frac{\sum_{i=1}^{R}\,\left|x_{ij}-\bar{x}_{j}\right|}{R}$$

$$SD_{j} = \sqrt{\frac{\sum_{i=1}^{R}\,\left(x_{ij}-\bar{x}_{j}\right)^{2}}{R-1}}$$

where $x_{ij}$ is the $i$th age estimate for the $j$th fish and $\bar{x}_{j}$ is the mean of the $R$ age estimates for the $j$th fish. The $AD_{j}$ and $SD_{j}$ may be scaled by $\bar{x}_{j}$ to produce the percent error (PE) and coefficient of variation (CV) for the $j$th fish, respectively; i.e., 

$$PE_{j} = \frac{AD_{j}}{\bar{x}_{j}}$$

$$CV_{j} = \frac{SD_{j}}{\bar{x}_{j}}$$

When $PE_{j}$ and $CV_{j}$ are averaged across all $n$ fish they produce the overall measures of precision called *average percent error* [$APE$; @beamishMethodComparingPrecision1981] and *average coefficient of variation* [$ACV$; @changStatisticalMethodEvaluating1982]. These measures are usually multiplied by 100 and expressed as a percentage. For example, the formulae for $APE$ and $ACV$ are

$$APE = 100\times\frac{\sum_{j=1}^{n}\, PE_{j}}{n}$$

$$ACV = 100\times\frac{\sum_{j=1}^{n}\, CV_{j}}{n}$$

When $R\!=\!2$, $ACV=\sqrt{2}\times APE$ [@changStatisticalMethodEvaluating1982; @kimuraQualityControlAge2005] and, thus, $ACV$ and $APE$ only differ by a constant value and provide functionally the same information about precision among age estimates. For $R\!>\!2$, $PE_{j}$ is directly proportional to $CV_{j}$ [@changStatisticalMethodEvaluating1982]. However, this proportionality depends on $\bar{x}_{j}$ and, thus, there is no constant proportionality between $APE$ and $ACV$, though they will likely be strongly correlated [@kimuraQualityControlAge2005].

Percent agreement, $APE$, and $ACV$ are the most commonly used measures of precision [@campanaAccuracyPrecisionQuality2001; @morisonQualityIssuesUse2005]. Percent agreement has been criticized as a useful composite measure of precision, largely because it varies widely among species and among ages within a species [@beamishMethodComparingPrecision1981; @kimuraBetweenreaderBiasVariability1991; @campanaGraphicalStatisticalMethods1995; @campanaAccuracyPrecisionQuality2001; @maceinaCurrentStatusReview2007]. Despite these critiques and likely due to its simplicity, @morisonQualityIssuesUse2005 found that 49% of 53 laboratories from 23 countries used percent agreement as a measure of precision among estimated ages. @beamishMethodComparingPrecision1981 proposed the $APE$ to address the shortcomings of the percent agreement. @changStatisticalMethodEvaluating1982 introduced $ACV$, though he called it $CV$, as a better alternative to the $APE$ because the standard deviation is a better estimator (unbiased and consistent) of variability than the absolute deviation, though @kimuraBetweenreaderBiasVariability1991 noted that this was only true if the age estimates were normally distributed.

In a review of 131 papers that reported precision values for fish age estimates, @campanaAccuracyPrecisionQuality2001 found that most papers used the ACV (57%) to measure precision, though APE and ACV were used almost equally for studies of annual age and ACV was used predominantly (84%) when estimating daily age from otoliths. The median and modal ACV across 117 studies deemed to have valid precision estimates were 7.6% and 5%, respectively. No significant differences in precision were found among calcified structures used to estimate annual age. @campanaAccuracyPrecisionQuality2001 reiterated that there is a direct conversion between ACV and APE when $R\!=\!2$ and that both measures are "equally sensitive to precision differences among agers." From this, @campanaAccuracyPrecisionQuality2001 stated "it is not self-evident that one measure [APE or ACV] is to be preferred over the other." From his literature review and informal discussions with scientists from fish ageing laboratories, @campanaAccuracyPrecisionQuality2001 concluded that an ACV of 5% would represent reasonable precision for many fish of moderate longevity and complexity of structure interpretation.

Other metrics of precision have been proposed or could be derived using similar logic. @changStatisticalMethodEvaluating1982 also introduced the index of precision for the $j$th fish as $D_{j}=\frac{ACV_{j}}{\sqrt{R}}$. @kimuraQualityControlAge2005 suggested, based on distributional theory, that the median age estimate for the $j$th fish ($\tilde{x}_{j}$) should be used instead of $\bar{x}_{j}$ for $PE_{j}$. Presumably the same argument can be applied to $CV_{j}$. This change results in a modified percent error and coefficient of variation for the $j$th fish; i.e., 

$$PE_{j}^{*} = \frac{\frac{\sum_{i=1}^{R}\,\left|x_{ij}-\tilde{x}_{j}\right|}{R}}{\tilde{x}_{j}}$$

$$CV_{j}^{*} = \frac{\sqrt{\frac{\sum_{i=1}^{R}\,\left(x_{ij}-\bar{x}_{j}\right)^{2}}{R-1}}}{\tilde{x}_{j}}$$ 

@bauerlienPrecisionCalcifiedStructures2018] suggested that if the variability among age estimates is not related to the age of the fish then $AD_{j}$ may be an appropriate measure of variability, as compared to $PE_{j}$. Similar arguments suggest that $SD_{j}$ may be an appropriate measure of variability, as compared to $CV_{j}$. Averaging these measures across all $n$ fish gives five alternative measures of precision among age estimates -- *average index of precision* [$D$; @changStatisticalMethodEvaluating1982], *average modified percent error* ($APE^{*}$), *average modified coefficient of variation* ($ACV^{*}$), *average absolute deviation* [$AAD$; @bauerlienPrecisionCalcifiedStructures2018], and *average standard deviation* ($ASD$). All but the $AAD$ and $ASD$ are typically multiplied by 100 and reported as a percentage.

Not suprisingly there are predictable relationships between several of these measures. When $R\!=\!2$, $ASD=\sqrt{2}\times AAD$, $ACV=ACV^{*}$ and $APE=APE^{*}$ because $\bar{x}_{j}=\tilde{x}_{j}$, and $APE=D$ [@campanaGraphicalStatisticalMethods1995]. Thus, when $R\!=\!2$, $ACV$, $APE$, $ACV^{*}$, $APE^{*}$, and $D$ provide functionally the same information about precision among age estimates. Similarly, $AAD$ and $ASD$ provide functionally the same information about precision among $R\!=\!2$ age estimates. For $R\!>\!2$, $ACV$ and $D$ are proportional and, thus, do not provide functionally different information about precision among age estimates.

It has been more than two decades since @campanaAccuracyPrecisionQuality2001 reviewed the use of precision metrics in the published literature and made recommendation for their use. It has also been 15 years since @maceinaCurrentStatusReview2007 reported on a survey of fisheries scientists with respect to their use of precision metrics. In relatively recent years, @bauerlienPrecisionCalcifiedStructures2018 suggested that using a single summary precision metric may not be good practice and @buckmeierValidationAnnualDaily2017 described how the ASD may be more appropriate than the ACV in some instances. Given the length of time since the last synthetic review of precision metrics and these newly raised questions, we report here on our comprehensive review of papers published since 2002 that reported age precision metrics and our extended analyses of data from multiple age interpretations reported in a variety of published papers. Our overall goal is to summarize the use and value of precision metrics since 2001, show results for precision metrics that are not typically used in the literature, and to provide specific recommendations on the use of precision metrics with respect to fish ageing studies. Specifically, we will answer the following questions from our review of the literature:

1. How often are each of the seven precision metrics introduced above used?
1. What is the distribution and summary statistics of ACV values reported in the literature?
1. Do ACV values reported in the literature differ by type of comparison (between or within interpreter), number of repeated interpretations (i.e., $R$), calcified structure, range of ages, sample size, or other characteristics of the fish (e.g., taxonomic category) or study (e.g., preparation method for the structure).
1. How often did the authors check for no bias before computing the precision metric?
1. How often did the authors check for a relationship between the precision metric and age?
1. How often was the precision metric related to age (when this relationship was examined)?

Under the *a priori* assumptions that only percent agreement, $APE$, and $ACV$ will be used extensively, few papers will have tested for bias prior to computing the precision metric, and few papers will have tested for a relationship between the precision metric and age, we will also answer the following questions from an extended analysis of some published data sets:

1. How are the various precision metrics related (beyond the known relationships identified above)?
1. How often is a bias detected (and, thus, precision should not be calculated)?
1. How often is the precision metric related to age (and, thus, a single overall measure of precision should not be calculated)?
1. What kind of relationship (linear, quadratic, or more complicated) between precision metric and age is most common?


# [A]Methods
[C]*Literature Review.*-- XXX


[C]*Extended Analyses.*-- XXX



######## WILL BE FLESHED OUT

# [A]Results
## [B]Literature Review

#### Sample Characteristics
```{r CALC_n_by_year}
## Sample size by years ----
SUMLR_n_years <- LR %>%
  group_by(pubyear,pubyear5) %>%
  summarize(n=n()) %>%
  ungroup()

SUMLR_n_years5 <- SUMLR_n_years %>%
  group_by(pubyear5) %>%
  summarize(minyr=min(pubyear),
            maxyr=max(pubyear),
            maxn=max(n),
            n_ests=sum(n))
SUMLR_n_years5

SUMLRBS_n_years <- LRBS %>%
  group_by(pubyear,pubyear5) %>%
  summarize(n=n()) %>%
  ungroup()
SUMLRBS_n_years5 <- SUMLRBS_n_years %>%
  group_by(pubyear5) %>%
  summarize(n_pubs=sum(n))
SUMLRBS_n_years5

SUM_n_years5 <- SUMLR_n_years5 %>%
  left_join(SUMLRBS_n_years5) %>%
  mutate(nlbl=paste0(n_ests," estimates in\n",n_pubs," publications"))
SUM_n_years5
```

TEXT HERE
```{r Figure_n_by_year, fig.width=fw2, fig.height=fh2}
ggplot() +
  geom_bar(data=SUMLR_n_years,mapping=aes(x=pubyear,y=n,fill="Estimates"),
           stat="identity",color="black",width=0.8,size=0.3) +
  geom_bar(data=SUMLRBS_n_years,mapping=aes(x=pubyear,y=n,fill="Publications"),
           stat="identity",width=0.6,size=0.05) +
  scale_y_continuous(name="Frequency",expand=expansion(mult=c(0,0.1)),
                     breaks=seq(0,100,10)) +
  scale_x_continuous(name="Publication Year",expand=expansion(mult=0.02),
                     breaks=seq(1995,2020,5)) +
  scale_fill_manual(values=c("Publications"="gray30","Estimates"="gray70")) +
  geom_segment(data=SUM_n_years5,mapping=aes(x=minyr-0.4,xend=maxyr+0.4,
                                               y=maxn+3,yend=maxn+3)) +
  geom_text(data=SUM_n_years5,
            mapping=aes(x=(minyr+maxyr)/2,y=maxn+3,label=nlbl),
            vjust=-0.1,size=3) +
  theme(legend.position=c(0,1),legend.justification=c(0,1),legend.box="none")

fn <- file.path(wdir,"docs","Figs",knitr::opts_current$get()$label)
if (saveTIFFs) ggsave(file=paste0(fn,".tiff"),dpi=300,scale=1,
                      width=fw2,height=fh2,units="in")
if (savePDFs) ggsave(file=paste0(fn,".pdf"),dpi=1000,scale=1,
                      width=fw2,height=fh2,units="in")
figs(name= knitr::opts_current$get()$label,"Number of individual estimates and number of publications with precision estimates by year from 1996-2020 used in the literature review. Number of estimates and publications were also shown for five year periods.")
```

`r figs("Figure_n_by_year")`

```{r CALC_n_by_class_structure}
## Sample size by class ----
## Removed holocephali and petromyzonti because n was so small
tmp <- xtabs(~class,data=LR)

SUMLR_n_class_strux <- LR %>%
  filter(class %in% c("Actinopteri","Elasmobranchii")) %>%
  group_by(class,structure) %>%
  summarize(n=n()) %>%
  mutate(Percent=n/sum(n)*100,
         plbl=paste0(formatC(Percent,format="f",digits=0),"%")) %>%
  ungroup()
SUMLR_n_class_strux
```

```{r Figure_n_by_class_structure, fig.width=fw1, fig.height=fh1}
ggplot(data=SUMLR_n_class_strux,
       mapping=aes(x=structure,y=n,fill=class)) +
  geom_bar(stat="identity",color="black",width=0.8,size=0.3) +
  scale_y_continuous(name="Frequency of Precision Estimates",
                     expand=expansion(mult=c(0,0.05))) +
  scale_x_discrete(name="Calcified Structure") +
  scale_fill_manual(values=c("Actinopteri"="gray70",
                             "Elasmobranchii"="gray30")) +
  theme(legend.position=c(1,1),legend.justification=c(1,1),legend.box="none")

fn <- file.path(wdir,"docs","Figs",knitr::opts_current$get()$label)
if (saveTIFFs) ggsave(file=paste0(fn,".tiff"),dpi=300,scale=1,
                      width=fw2,height=fh2,units="in")
if (savePDFs) ggsave(file=paste0(fn,".pdf"),dpi=1000,scale=1,
                      width=fw2,height=fh2,units="in")
figs(name=knitr::opts_current$get()$label,paste("Number of individual precision estimates by calcified structure type separated by major taxonomic class.",FSA::kCounts(tmp[['Holocephali']],capitalize=TRUE),"and",FSA::kCounts(tmp[['Petromyzonti']]),"estimates for Holocephali and Petromyzonti are not included."))
```

`r figs("Figure_n_by_class_structure")`

```{r CALC_P_by_type_structure}
## Sample size by type ----
## Removed "both" because n was so small
tmp <- xtabs(~type,data=LR)

tmp1 <- xtabs(~structure+type,data=droplevels(filter(LR,type!="Both")))
( chi <- chisq.test(tmp1) )
tmp2 <- NCStats::chisqPostHoc(chi)
tmp2$comparison[which(tmp2$adj.p<0.05)]

SUM_np_strux_type <- LR %>%
  filter(type!="Both") %>%
  group_by(structure,type) %>%
  summarize(freq=n()) %>%
  mutate(perc=freq/sum(freq)*100) %>%
  ungroup()
SUM_np_strux_type2 <- SUM_np_strux_type %>%
  filter(type=="Within") %>%
  mutate(lets=c("b","bc","bc","c","a","ab"),
         plbl=paste0(formatC(perc,format="f",digits=0),"%"),
         nlbl=paste0("n=",freq))
```

```{r Figure_P_by_type_structure, fig.width=fw1, fig.height=fh1}
ggplot() +
  geom_bar(data=SUM_np_strux_type,mapping=aes(x=structure,y=perc,fill=type),
           stat="identity",color="black",width=0.8,size=0.3) +
  scale_y_continuous(name="Percentage of Precision Estimates",
                     expand=expansion(mult=c(0,0.04))) +
  scale_x_discrete(name="Calcified Structure") +
  scale_fill_manual(values=c("Between"="gray70","Within"="gray30")) +
  annotate(geom="text",x=1,y=100,label="Between",
           angle=90,size=2.5,hjust=1.1) +
  annotate(geom="text",x=1,y=0,label="Within",
           angle=90,size=2.5,color="white",hjust=-0.1) +
  geom_text(data=SUM_np_strux_type2,mapping=aes(x=structure,y=perc,label=plbl),
            vjust=-0.3,size=2.5) +
  geom_text(data=SUM_np_strux_type2,mapping=aes(x=structure,y=perc,label=lets),
            vjust=1.3,size=2.5,color="white") +
  geom_text(data=SUM_np_strux_type2,mapping=aes(x=structure,y=100,label=nlbl),
            vjust=-0.3,size=2.5) +
  theme(legend.position="none")

fn <- file.path(wdir,"docs","Figs",knitr::opts_current$get()$label)
if (saveTIFFs) ggsave(file=paste0(fn,".tiff"),dpi=300,scale=1,
                      width=fw2,height=fh2,units="in")
if (savePDFs) ggsave(file=paste0(fn,".pdf"),dpi=1000,scale=1,
                      width=fw2,height=fh2,units="in")
figs(name=knitr::opts_current$get()$label,paste("Percentage of individual precision estimates within calcified structure types that were within-reader estimates. Structures with the same letters have statistically equal percent of within-reader estimates. Overall sample size for each structure is shown above the bars.",FSA::kCounts(tmp[["Both"]],capitalize=TRUE),"estimates that combined within- and between-reader estimates are not included."))
```

`r figs("Figure_P_by_type_structure")`

```{r CALC_n_by_R}
SUMLR_n_R <- LR %>%
  group_by(Rcat4) %>%
  summarize(freq=n()) %>%
  mutate(perc=freq/sum(freq)*100)
```

```{r Figure_n_by_R, fig.width=fw1, fig.height=fh1}
ggplot(data=SUMLR_n_R,mapping=aes(x=Rcat4,y=freq)) +
  geom_bar(stat="identity",color="black",fill="gray30",width=0.8,size=0.3) +
  scale_x_discrete(name="R (Number of Repeated Readings)") +
  scale_y_continuous(name="Frequency of Precision Estimates",
                     expand=expansion(mult=c(0,0.02)))

fn <- file.path(wdir,"docs","Figs",knitr::opts_current$get()$label)
if (saveTIFFs) ggsave(file=paste0(fn,".tiff"),dpi=300,scale=1,
                      width=fw2,height=fh2,units="in")
if (savePDFs) ggsave(file=paste0(fn,".pdf"),dpi=1000,scale=1,
                      width=fw2,height=fh2,units="in")
figs(name=knitr::opts_current$get()$label,paste("Number of individual precision estimates by the number of repeated readings (R). The maximum number of repeated readings was R=9."))
```

`r figs("Figure_n_by_R")`

```{r CALC_P_by_R_year}
## Sample size by R
tmp <- xtabs(~pubyear5+Rcat4,data=LR)
chisq.test(tmp)
tmp <- xtabs(~pubyear5+Rcat3,data=LR)
chi1 <- chisq.test(tmp)
NCStats::chisqPostHoc(chi1)


SUMLR_n_R_year5 <- LR %>%
  group_by(pubyear5,Rcat4) %>%
  summarize(freq=n()) %>%
  mutate(perc=freq/sum(freq)*100)

SUMLR_n_R_year5a <- SUMLR_n_R_year5 %>%
  summarize(freq=sum(freq)) %>%
  mutate(nlbl=paste0("n=",freq))
```

```{r Figure_P_by_R_year, fig.width=fw1, fig.height=fh1}
ggplot() +
  geom_bar(data=SUMLR_n_R_year5,mapping=aes(x=pubyear5,y=perc,fill=Rcat4),
           stat="identity",color="black",width=0.8,size=0.3,
           position=position_stack(reverse=TRUE)) +
  scale_x_discrete(name="R (Number of Repeated Readings)") +
  scale_y_continuous(name="Frequency of Precision Estimates",
                     expand=expansion(mult=c(0,0.04))) +
  scale_fill_manual(values=c("2"="gray20","3"="gray50","4+"="gray80")) +
  geom_text(data=SUMLR_n_R_year5a,mapping=aes(x=pubyear5,y=100,label=nlbl),
            vjust=-0.3,size=2.5) +
  annotate(geom="text",x=1,y=58/2,label="R=2",size=2.5,color="white") +
  annotate(geom="text",x=1,y=58+42/2,label="R=3",size=2.5) +
  annotate(geom="text",x=5,y=100-8.75/2,label="R=4+",size=2.5) +
  theme(legend.position="none")

fn <- file.path(wdir,"docs","Figs",knitr::opts_current$get()$label)
if (saveTIFFs) ggsave(file=paste0(fn,".tiff"),dpi=300,scale=1,
                      width=fw2,height=fh2,units="in")
if (savePDFs) ggsave(file=paste0(fn,".pdf"),dpi=1000,scale=1,
                      width=fw2,height=fh2,units="in")
figs(name=knitr::opts_current$get()$label,paste("Percentage of individual precision estimates within each 5-year period by the number of repeated readings (R)."))
```

`r figs("Figure_P_by_R_year")`













[C]*Extended Analyses.*-- XXX

######## WILL BE FLESHED OUT

# [A]Discussion
## [B]Subsection

######## WILL BE FLESHED OUT


# [A]Acknowledgments

######## WILL BE FLESHED OUT


# [A]References

######## Need to fix species capitalization